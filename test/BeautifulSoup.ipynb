{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pprint\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "\t<head>\n",
    "\t\t<title>The Dormouse's story</title></head>\n",
    "\t<body>\n",
    "\t\t<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\t\t<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "\t\t<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "\t\t<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "\t\t<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "\t\tand they lived at the bottom of a well.</p>\n",
    "\n",
    "\t\t<p class=\"story\">...</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nThe Dormouse's story\\n\\nThe Dormouse's story\\nOnce upon a time there were three little sisters; and their names were\\n\\t\\tElsie,\\n\\t\\tLacie and\\n\\t\\tTillie;\\n\\t\\tand they lived at the bottom of a well.\\n...\\n\\n\\n\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html_doc을 파싱하기위한 soup 객체 생성\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "# pp.pprint(soup)\n",
    "# 아래와 같다.\n",
    "# print(soup.prettify())\n",
    "# soup.text\n",
    "# print(soup.find('a').text)  # find  find_all  select   select_one\n",
    "# print(re.findall(r'<a.+>(.+)</a>',html_doc)) # 위의 명령을 정규표현식으로~\n",
    "# soup.title\n",
    "# soup.title.name\n",
    "# soup.title.string\n",
    "# soup.title.parent.name\n",
    "# soup.p.name\n",
    "# soup.p\n",
    "# soup.p['class'] # class는 속성이다!!\n",
    "# soup.a\n",
    "# soup.find_all('a') # soup.find_all('a').text를 하면 a태그의 모든 text가 보인다?? NO!!!\n",
    "\n",
    "## a태그의 모든 text 뽑아내려면 반복문 사용하면 가능! \"soup.find_all('a')\" 가 객체가 반복자료형이기 때문에 가능하다!\n",
    " # 반복자료형이라는 것이 리스트 형태인지 그렇다면 아래에 ,로 구분이 안되는데???????★\n",
    "## a_text = [i.text for i in soup.find_all('a')]\n",
    "## a_text\n",
    "    \n",
    "## soup.find_all('a',{'id':'link2'})   # soup.find_all('태그명',{'속성':'값'})\n",
    "# soup.find(id=\"link3\")   # soup.select('a[id=link2]')   #  soup.select('태그명[속성=값]')\n",
    "# for link in soup.find_all('a'):\n",
    "#     print(link.get('href'))\n",
    "# print(soup.get_text())\n",
    "\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버스카드 망가진 여성에 “그냥 타세요”…친절 베푼 버스기사가 받은 선물\n",
      "\"권도형 측, SEC 소송 대응에 '리플 증권 아니다' 판결 인용\"\n",
      "3일에 한 번 대변 보세요?… 뇌 노화 위험 커\n",
      "권영세 \"호기심에 3천~4천만 원\" 김홍걸 \"외통위라 문제없다\"‥코인 해명 들어보니\n",
      "전북서 서이초 교사 추모제…빗속 500명 모여\n",
      "\"외지 학생들 대거 응시해 현지 학생들 탈락\"…中학부모들 시위\n",
      "해병대 비판 대신 재발방지 강조…故채수근 상병 부모의 편지\n",
      "'소포 공포' 에 신고 1,600건…대만 측 \"최초 발송지 중국\"\n",
      "'천공 아니다'에 풍수 공방 더 격화…\"조선시대냐\" vs \"이재명도 만나\"\n",
      "‘침대는 과학’이란 말은 옛말, 요즘은 이 기술이 불면증 돕는다 [방영덕의 디테일]\n",
      "해병대 채수근 상병 영결식… 엄마는 실신했다\n",
      "치매 막으려면 보청기 미루지 마세요\n",
      "“남부는 펄펄 끓는 지옥인데”…伊 북부는 테니스공 만한 우박\n",
      "응급 복구도 안 끝났는데…“추가 피해 막아라”\n",
      "[D리포트] 입 연 신림역 피의자 \"남들도 나처럼 불행하게 만들고 싶었다\"\n",
      "‘수상한 국제 우편물’ 신고 천6백여 건…판매 실적 부풀리기?\n",
      "폭우에 폭염, 전쟁까지…식량 위기 가속화 [경제대기권]\n",
      "춘천시 서면 춘천댐 인근 도로 붕괴…차량통제\n",
      "국힘 “김은경 혁신위 목불인견” vs 민주 “최은순씨 법정구속 사필귀정”\n",
      "주춤하던 장맛비 다시 시작..다음주 월요일까지\n",
      "세상 가장 높은 곳에서 만들어진 하나뿐인 와인 [전형민의 와인프릭]\n",
      "‘침대는 과학’이란 말은 옛말, 요즘은 이 기술이 불면증 돕는다 [방영덕의 디테일]\n",
      "갈등 폭발한 이민국가들…한국의 갈 길은? [탐사보도 뉴스프리즘]\n",
      "[D리포트] 휴대전화 도난 주의보…유심칩으로 현금 이체까지\n",
      "[주말&문화] 대동여지도부터 근현대 명작까지…대학 박물관에 이런 보물이?\n",
      "[뉴스추적] 북한 순항미사일에 핵무기 탑재?…미국이 '전쟁' 언급한 이유는\n",
      "싱가포르 최악 가정부 학대 사망…“24kg 몸, 뼈밖에 없었다” [여기는 동남아]\n",
      "인력난 기업에 ‘단비’… “적극성·성실성에 매출액도 증가” [심층기획-실버 푸어 시대 경고음]\n",
      "'2023 WORLD K-POP FESTIVAL' 개막\n",
      "채수근 상병, 대전현충원서 영면\n",
      "춘천 서면 붕괴된 도로\n",
      "'눈물바다 속 작별' 별이 된 故 채수근 상병\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 항목 중 한 가지 선택하여 뉴스기사(목록) 가져오기\n",
    "import requests\n",
    "daum_news_url = 'https://news.daum.net/'\n",
    "daum_news_data = requests.get(daum_news_url).text\n",
    "data_html = BeautifulSoup(daum_news_data,'html.parser') # 가지고 온 정보의 .contents & .text가 html형식이므로(url이 왭페이지이기 때문) html로 parser해준다!!\n",
    "# print(data_html.prettify)\n",
    "\n",
    "# print(data_html)\n",
    "# data_html.link['href']\n",
    "# /html/body/div[2]/main/section/div/div[1]/div[1]/ul/li[2]/div/div/strong/a/text()\n",
    "for i in data_html.select('div>div>strong>a'):\n",
    "    print(i.text.strip())\n",
    "\n",
    "# 질문 사진 있음 <a>태그에 안들어가있는 헤드라인이 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
